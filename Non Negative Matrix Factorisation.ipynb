{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non Negative Matrix Factorisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this project will be to explore a Non Negative Matrix Factorisation (NMF) algorithm from scratch. The algorithm will consist of a euclidean and kl-divergence cost function optimised using a multiplicative update approach. My efforts in this project were part of the coursework of Advanced Machine Learning from the Master of Data Science offered by the University of Sydney. Throughout this notebook, I will paste snippets of the report that I wrote in collaboration with my assignment partner Joshua Huang.\n",
    "\n",
    "Key achievements:\n",
    "1. Investigated and wrote a Non Negative Matrix Factorisation algorithm from scratch.\n",
    "2. First time working with images in a machine learning application.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over the last few decades, Non-Negative Matrix Factorisation (NMF) has been demonstrated as a potential unsupervised learning and decomposition technique that can be used across a wide range of applications including image recognition, speech recognition and natural language processing. The major difference between NMF and other matrix decomposition algorithms is that all matrices involved in NMF are required to be non-negative. This is a reasonable constraint as many observations in the physical world are represented by non-negative numbers. As with all machine learning algorithms however, NMF has been found to perform differently depending on the underlying application, with one specific variable being the distribution of noise present in the data. Consequently, a number of researchers in the field have proposed various modifications to NMF, namely through the use of different cost functions and optimisation procedures. \n",
    "\n",
    "This project thus aims to validate the robustness of the standard NMF algorithms which use the squared Euclidean distance and Kullback-Leibler divergence cost function to different types of noise. Specifically, the importance of pre-processing and robustness to noise generated from a Gaussian and Laplacian distribution will be investigated. The datasets used for experimentation will consist of the ORL and YaleB dataset. All experimentation scenarios will be applied to both datasets and evaluated using three different robustness metrics (Relative Reconstruction Errors, Average Accuracy and Normalised Mutual Information) on each algorithmâ€™s performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notebook will use two image datasets - CroppedYaleB and ORL. \n",
    "\n",
    "CroppedYaleB can be found here:\n",
    "http://vision.ucsd.edu/~leekc/ExtYaleDatabase/ExtYaleB.html\n",
    "\n",
    "and ORL here:\n",
    "http://www.cl.cam.ac.uk/Research/DTG/attarchive:pub/data/att_faces.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample image from ORL dataset:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "#functions for loading the image datasets\n",
    "\n",
    "def load_data(root='C:/Users/Harrison/Documents/Uni Work/Advanced Machine Learning/data/CroppedYaleB', reduce=4):\n",
    "    images, labels = [], []\n",
    "    for i, person in enumerate(sorted(os.listdir(root))):\n",
    "        if not os.path.isdir(os.path.join(root, person)):\n",
    "            continue        \n",
    "        for fname in os.listdir(os.path.join(root, person)):  \n",
    "            # Remove background images in Extended YaleB dataset.\n",
    "            if fname.endswith('Ambient.pgm'):\n",
    "                continue            \n",
    "            if not fname.endswith('.pgm'):\n",
    "                continue                \n",
    "            # load image.\n",
    "            img = Image.open(os.path.join(root, person, fname))\n",
    "            img = img.convert('L') # grey image.\n",
    "            # reduce computation complexity.\n",
    "            img = img.resize([s//reduce for s in img.size])\n",
    "            # preprocessing (normalisation)\n",
    "            img = (img-np.min(img))/(np.max(img)-np.min(img))\n",
    "            # convert image to numpy array.\n",
    "            img = np.asarray(img).reshape((-1,1))           \n",
    "            # collect data and label.\n",
    "            images.append(img)\n",
    "            labels.append(i)\n",
    "    # concate all images and labels.\n",
    "    images = np.concatenate(images, axis=1)\n",
    "    labels = np.array(labels)\n",
    "    return images, labels\n",
    "\n",
    "def load_data_without_normalisation(root='C:/Users/Harrison/Documents/Uni Work/Advanced Machine Learning/data/CroppedYaleB', reduce=4):\n",
    "    images, labels = [], []\n",
    "    for i, person in enumerate(sorted(os.listdir(root))):\n",
    "        if not os.path.isdir(os.path.join(root, person)):\n",
    "            continue        \n",
    "        for fname in os.listdir(os.path.join(root, person)):  \n",
    "            # Remove background images in Extended YaleB dataset.\n",
    "            if fname.endswith('Ambient.pgm'):\n",
    "                continue            \n",
    "            if not fname.endswith('.pgm'):\n",
    "                continue                \n",
    "            # load image.\n",
    "            img = Image.open(os.path.join(root, person, fname))\n",
    "            img = img.convert('L') # grey image.\n",
    "            # reduce computation complexity.\n",
    "            img = img.resize([s//reduce for s in img.size])\n",
    "            # preprocessing (normalisation)\n",
    "            img = (img-np.min(img))/(np.max(img)-np.min(img))\n",
    "            # convert image to numpy array.\n",
    "            img = np.asarray(img).reshape((-1,1))           \n",
    "            # collect data and label.\n",
    "            images.append(img)\n",
    "            labels.append(i)\n",
    "    # concate all images and labels.\n",
    "    images = np.concatenate(images, axis=1)\n",
    "    labels = np.array(labels)\n",
    "    return images, labels\n",
    "\n",
    "#Sample images from both datasets\n",
    "V_orl, Y = load_data(root='C:/Users/Harrison/Documents/Uni Work/Advanced Machine Learning/Assignment 1/data/ORL', reduce=3)\n",
    "#print('ORL dataset: X.shape = {}, Y.shape = {}'.format(V.shape, Y.shape))  #reshape numbers: 37, 30\n",
    "\n",
    "image_original = V_orl[:,0].reshape(37,30)\n",
    "plt.imshow(image_original, cmap=plt.cm.gray)\n",
    "print('Sample image from ORL dataset:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample image from Yale dataset\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#load the YaleB Database\n",
    "V_yale, Y = load_data(root='C:/Users/Harrison/Documents/Uni Work/Advanced Machine Learning/Assignment 1/data/CroppedYaleB', reduce=6)\n",
    "#print('Extended YalB dataset: X.shape = {}, Y.shape = {}'.format(V.shape, Y.shape)) #reshape numbers 32, 28\n",
    "\n",
    "image_original = V_yale[:,0].reshape(32,28)\n",
    "plt.imshow(image_original, cmap=plt.cm.gray)\n",
    "print('Sample image from Yale dataset:')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The functions below are Non Negative Matrix Factorisation algorithms written using standard squared Euclidean distance and KL Divergence cost functions. The multiplicative update rules are written to gaurantee optimisation. According to the academic literature, Euclidean NMF is more robust against gaussian noise and less robust against laplacian compared to KL-Divergence NMF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for NMF using a euclidean based cost function and a multiplicative update algorithm\n",
    "\n",
    "def NMF_euc(V, max_iterations):\n",
    "    n = V.shape[0]\n",
    "    m = V.shape[1]\n",
    "    r = np.linalg.matrix_rank(V)\n",
    "    W = np.random.rand(n, r)\n",
    "    H = np.random.rand(r, m)        \n",
    "    records = []\n",
    "    iteration_count = 0\n",
    "    conv_criteria = []\n",
    "    stop_flag = 0\n",
    "#stop criteria maxes at specified max_iterations or when ratio of the\n",
    "#difference in loss is between 0.99 and 1 for last 20 iterations(i.e. convergence)\n",
    "    while iteration_count < max_iterations and stop_flag != 1:\n",
    "        W_stationary = W\n",
    "        H_stationary = H\n",
    "        top_H = np.dot(W_stationary.T, V)\n",
    "        bottom_H = W_stationary.T.dot(np.dot(W_stationary, H_stationary))\n",
    "        for i in range(H.shape[0]):\n",
    "            for j in range(H.shape[1]):\n",
    "                H[i][j] = H_stationary[i][j] * top_H[i][j] / bottom_H[i][j]  \n",
    "        H_stationary = H\n",
    "        W_stationary = W\n",
    "        top_W = np.dot(V, H_stationary.T)\n",
    "        bottom_W = W_stationary.dot(np.dot(H_stationary, H_stationary.T))\n",
    "        for i in range(W.shape[0]):\n",
    "            for j in range(W.shape[1]):\n",
    "                W[i][j] = W_stationary[i][j] * top_W[i][j] / bottom_W[i][j]\n",
    "        loss = np.sum((V - W.dot(H))**2)   \n",
    "        records.append(loss)\n",
    "        iteration_count += 1\n",
    "        ##print('Iteration %s: %s' %(iteration_count, loss))\n",
    "        if iteration_count > 100:\n",
    "            try:\n",
    "                conv_1 = abs(records[-2] - records[-1])\n",
    "                conv_2 = abs(records[-3] - records[-2])\n",
    "                convergence_value = conv_1/conv_2\n",
    "                conv_criteria.append (convergence_value)\n",
    "                last_20_1 = np.array(conv_criteria[-20:]) > 0.99 \n",
    "                last_20_2 = np.array(conv_criteria[-20:]) < 1  \n",
    "                if np.sum(last_20_1) == np.sum(last_20_2):\n",
    "                    stop_flag = 1\n",
    "                else:\n",
    "                    stop_flag = 0\n",
    "            except:\n",
    "                next\n",
    "    return W,H\n",
    "\n",
    "#KL Divergence NMF\n",
    "def NMF_div(V, max_iterations):\n",
    "    n = V.shape[0]\n",
    "    m = V.shape[1]\n",
    "    r = np.linalg.matrix_rank(V)\n",
    "    W = np.random.rand(n, r)\n",
    "    H = np.random.rand(r, m)        \n",
    "    records = []\n",
    "    iteration_count = 0\n",
    "    conv_criteria = []\n",
    "    stop_flag = 0\n",
    "    while iteration_count < max_iterations and stop_flag != 1:\n",
    "        W_stationary = W\n",
    "        H_stationary = H\n",
    "        top_H = W_stationary.T.dot(V/np.dot(W_stationary, H_stationary))\n",
    "        bottom_H = np.dot(W_stationary.T, np.ones(V.shape))\n",
    "        for i in range(H.shape[0]):\n",
    "            for j in range(H.shape[1]):\n",
    "                H[i][j] = H_stationary[i][j] * top_H[i][j] / bottom_H[i][j]  \n",
    "        H_stationary = H\n",
    "        W_stationary = W\n",
    "        top_W = np.dot((V/np.dot(W_stationary, H_stationary)), H_stationary.T)\n",
    "        bottom_W = np.dot(np.ones(V.shape),H_stationary.T)\n",
    "        for i in range(W.shape[0]):\n",
    "            for j in range(W.shape[1]):\n",
    "                W[i][j] = W_stationary[i][j] * top_W[i][j] / bottom_W[i][j]\n",
    "        z = V/(np.dot(W,H))\n",
    "        z[z<=0] = 0.001\n",
    "        loss = np.sum(V*np.log(z) - V + W.dot(H))\n",
    "        records.append(loss)\n",
    "        iteration_count += 1\n",
    "        #print(loss)\n",
    "        if iteration_count > 100:\n",
    "            try:\n",
    "                conv_1 = abs(records[-2] - records[-1])\n",
    "                conv_2 = abs(records[-3] - records[-2])\n",
    "                convergence_value = conv_1/conv_2\n",
    "                conv_criteria.append (convergence_value)\n",
    "                last_20_1 = np.array(conv_criteria[-20:]) > 0.99 \n",
    "                last_20_2 = np.array(conv_criteria[-20:]) < 1  \n",
    "                if np.sum(last_20_1) == np.sum(last_20_2):\n",
    "                    stop_flag = 1\n",
    "                else:\n",
    "                    stop_flag = 0\n",
    "            except:\n",
    "                next\n",
    "    return W,H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These functions will be used to measure the robustness of each algorithm i.e robustness evaluation metrics (accuracy,\n",
    "#relative reconstruction errors (RRE) and Normalised Mutual Information (NMI).\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "\n",
    "def assign_cluster_label(X, Y):\n",
    "    kmeans = KMeans(n_clusters=len(set(Y))).fit(X)\n",
    "    Y_pred = np.zeros(Y.shape)\n",
    "    for i in set(kmeans.labels_):\n",
    "        ind = kmeans.labels_ == i\n",
    "        Y_pred[ind] = Counter(Y[ind]).most_common(1)[0][0] # assign label.\n",
    "    return Y_pred\n",
    "\n",
    "#kmeans = KMeans(n_clusters=len(set(Y))).fit(V_recon.T)\n",
    "\n",
    "#Y_pred = assign_cluster_label(np.dot(W,H).T,Y)\n",
    "#acc = accuracy_score(Y, Y_pred)\n",
    "\n",
    "###Relative reconstruction errors (RRE)\n",
    "#RRE = np.linalg.norm(V-np.dot(W, H)) / np.linalg.norm(V)\n",
    "\n",
    "###NMI\n",
    "#nmi = normalized_mutual_info_score(Y, Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To investigate the differences between Euclidean Distance and KL Divergence NMF, different types of noise will be added to the images in both datasets. The noises used in this experiment will include gaussian, laplacian and sparse noise. Please see below:\n",
    "\n",
    "<img src=\"/files/Different Noises.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Noise functions\n",
    "\n",
    "def add_gaussian_noise(V, mean, std_dev):\n",
    "    V_noise = np.ones(V.shape)\n",
    "    for column in range(V.shape[1]):\n",
    "        gaussian_noise = np.random.normal(mean, std_dev, V.shape[0])\n",
    "        gaussian_noise[gaussian_noise<0] = 0\n",
    "        V_noise[:,column] = V[:,column] + gaussian_noise        \n",
    "    V_noise[V_noise<0] = 0\n",
    "    return V_noise\n",
    "        \n",
    "def add_laplac_noise(V, centre, scale):\n",
    "    laplac_noise = np.random.laplace(centre,scale,V.shape)\n",
    "    laplac_noise[laplac_noise<0] = 0\n",
    "    V_noise = V + laplac_noise\n",
    "    return V_noise\n",
    "\n",
    "def add_sparse_noise(V, width, height, reshape_1, reshape_2):\n",
    "    V_noise = []\n",
    "    for image in range(V.shape[1]):\n",
    "        img = V[:, image].reshape(reshape_1,reshape_2)\n",
    "        start_x = np.random.randint(0, reshape_2 - width)\n",
    "        start_y = np.random.randint(0, reshape_1 - height)\n",
    "        img[start_y: start_y+height, start_x:start_x+width] = 1\n",
    "        img = np.asarray(img).reshape((-1,1))\n",
    "        V_noise.append(img)\n",
    "    V_noise = np.concatenate(V_noise, axis=1)\n",
    "    return V_noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below can be described as three separate experiments. Each experiment will add a different type of noise to the dataset (Gaussian, Laplacian and Sparse* respectively) and measure the robustness of the algorithm against RRE, Accuracy and NMI. Within each experiment, the algorithm will be run 5 times and each metric will then be averaged and recorded.\n",
    "\n",
    "Each code will have the optional functions commented out. Feel free to activate them as appropriate. The commented-out code will include:\n",
    "1) Reading in the different datasets (ORL or YALEB)\n",
    "2) Switching between Euclidean or Divergence NMF algorithms\n",
    "3) Adding different types of noise (Gaussian, Laplacian and Sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extended YalB dataset: X.shape = (896, 2414), Y.shape = (2414,)\n",
      "Results:\n",
      "RRE mean: 0.1835163305672902\n",
      "Acc mean: 0.22265193370165748\n",
      "NMI mean: 0.3487073027375593\n"
     ]
    }
   ],
   "source": [
    "#load the ORL Database\n",
    "#V, Y = load_data(root='C:/Users/Harrison/Documents/Uni Work/Advanced Machine Learning/Assignment 1/data/ORL', reduce=3)\n",
    "#print('ORL dataset: X.shape = {}, Y.shape = {}'.format(V.shape, Y.shape))  #reshape numbers: 37, 30\n",
    "\n",
    "#load the YaleB Database\n",
    "V, Y = load_data(root='C:/Users/Harrison/Documents/Uni Work/Advanced Machine Learning/Assignment 1/data/CroppedYaleB', reduce=6)\n",
    "print('Extended YalB dataset: X.shape = {}, Y.shape = {}'.format(V.shape, Y.shape)) #reshape numbers 32, 28\n",
    "\n",
    "rre_results = []\n",
    "acc_results = []\n",
    "nmi_results = []\n",
    "\n",
    "for i in range(5):       \n",
    "    #subset = random.sample(range(V.shape[1]), int(0.9*V.shape[1])) #ORL dataset\n",
    "    subset = random.sample(range(V.shape[1]), int(0.15*V.shape[1])) #YaleB dataset, reduce dataset to reduce computational time\n",
    "    V_test = V[:, subset]\n",
    "    Y_test = Y[subset]\n",
    "        \n",
    "    #adding noise\n",
    "    ##gaussian noise\n",
    "    #V_noise = add_gaussian_noise(V_test, 0, 0.15)\n",
    "    \n",
    "    ##laplacian noise\n",
    "    V_noise = add_laplac_noise(V_test, 0, 0.2)\n",
    "    \n",
    "    ##sparse noise\n",
    "    #V_noise = add_sparse_noise(V_test, 10, 5, 37, 30) #if ORL dataset, using reduce = 3\n",
    "    #V_noise = add_sparse_noise(V_test, 10, 5, 32, 28 ) #if YaleB dataset, using reduce = 6\n",
    "    \n",
    "    #apply NMF\n",
    "    W, H = NMF_euc(V_noise, 500)\n",
    "    #W, H = NMF_div(V_noise, 500)\n",
    "    \n",
    "    #evaluation metrics\n",
    "    RRE = np.linalg.norm(V_noise-np.dot(W, H)) / np.linalg.norm(V_noise)\n",
    "    rre_results.append(RRE)\n",
    "    \n",
    "    Y_pred = assign_cluster_label(np.dot(W,H).T,Y_test)\n",
    "    acc = accuracy_score(Y_test, Y_pred)\n",
    "    acc_results.append(acc)\n",
    "    \n",
    "    nmi = normalized_mutual_info_score(Y_test, Y_pred)\n",
    "    nmi_results.append(nmi)\n",
    "    #print(nmi)\n",
    "    \n",
    "#evaluate results\n",
    "rre_mean = np.mean(rre_results)\n",
    "acc_mean = np.mean(acc_results)\n",
    "nmi_mean = np.mean(nmi_results)\n",
    "print(\"Results:\")\n",
    "print('RRE mean: %s' %(rre_mean))\n",
    "print('Acc mean: %s' %(acc_mean))\n",
    "print('NMI mean: %s' %(nmi_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following tables contain the results from the above experiments*:\n",
    "\n",
    "<img src=\"/files/ORL_Results.png\">\n",
    "\n",
    "<img src=\"/files/Yale_Results.png\">\n",
    "\n",
    "*Results are taken from the assignment at the time and therefore may not align with the coded results (experiment was not seeded, my bad!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discussion of Results\n",
    "\n",
    "From the analysis of results, adding noise was seen to have a considerable impact on the performance of both matrix factorization algorithms. Using the no noise metrics as the baseline, Gaussian Noise was seen to have equivalent impact on both Euclidean and KL Divergence NMF, recording an increase of ~0.07 in the RRE value. This is expected as both factorization algorithms perform considerably worse if the Gaussian noise exceeds a certain limit. In the ORL dataset the KL Divergence performed much better with Laplacian noise than the Euclidean distance. This is in stark contrast to the Laplacian noise results from the YaleB dataset, where the KL Divergence performed worse. This could be as a result of the YaleB dataset containing more corruptions than the ORL dataset (where the face is obscured due to poor lightning), or as a consequence of the Laplacian noise that was added separately in each experiment. As the Python algorithm initialized the noise randomly on each experimental iteration, more noise could have been added when testing the YaleB dataset. Furthermore, only 15% of the YaleB dataset was used due to computational reasons compared to the 90% used for the ORL dataset, which could explain the smaller discrepancies observed in YaleB. Both algorithms had similar performance with sparse noise as the noise value was much lower than the Gaussian and Laplacian noise added. \n",
    "\n",
    "Thorough analysis of the NMI and ACC also indicate a significant decrease between the dataset scores. As explained above this could be simply due to the structural differences of the data or methodologies used in obtaining the results. Both algorithms also had poor performance with Laplacian noise using these metrics, indicating that the higher noise bounds (greater probability of moderate to extreme outliers due to the distributionâ€™s fatter tails) were more likely to corrupt and affect the algorithmâ€™s performance than Gaussian noise. Sparse noise had a more minor  impact on performance as the quantity of noise was smaller. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion\n",
    "\n",
    "Thorough analysis of the proposed NMF methods have shown that the Euclidean cost metric is relatively on par with the KL Divergence metric. Whilst literature has dictated that KL Divergence is generally meant to be more robust to Gaussian and Laplacian noise, the results obtained within this experiment has proven otherwise. This could be as a result of structural differences between both datasets or due to the initialization method utilized within this experiment. Column-wise normalization was found to have minimal impact however it is likely that multiple experiments need to be conducted to confirm this result. \n",
    "\n",
    "The investigations undertaken by this paper have inspired various pathways for future work. This paper only looked at one type of normal and laplacian distribution (i.e. one combination of mean and standard deviation only). Future work would be to perform more experiments using gaussian and laplacian noise, but vary the underlying characteristics of each by shifting the mean and standard deviation or centre and scales respectively. This will give a more robust conclusion to whether Euclidean or KL-divergence performs better on which type of noise. In addition to this, more complex noise, following the idea of sparse noise could also be further investigated in future work. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Appendix for reconstructing the noisy images\n",
    "\n",
    "#reconstruct images with noise #ORL datasets\n",
    "image_original = V[:,0].reshape(37,30)\n",
    "plt.imshow(image_original, cmap=plt.cm.gray)\n",
    "\n",
    "#noisy_image = V_noise[:,0].reshape(37,30)\n",
    "plt.imshow(noisy_image, cmap=plt.cm.gray)\n",
    "\n",
    "#reconstruct images with noise #YaleB datasets\n",
    "image_original = V_subset[:,0].reshape(32,28) \n",
    "plt.imshow(image_original, cmap=plt.cm.gray)\n",
    "\n",
    "noisy_image = V_noise[:,0].reshape(32,28)\n",
    "plt.imshow(noisy_image, cmap=plt.cm.gray)\n",
    "\n",
    "#applying R\n",
    "r = 300\n",
    "W_final_chop = W_final[:,:r]\n",
    "H_final_chop = H_final[:r,:]\n",
    "recon_r = np.dot(W_final_chop, H_final_chop)\n",
    "noisy_image_r = recon_r[:,0].reshape(37,30)\n",
    "plt.imshow(noisy_image_r, cmap=plt.cm.gray)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
